version: '3.8'

services:
  # Frontend - Vue.js/Quasar
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "8080:80"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    environment:
      - NODE_ENV=development
      - VITE_API_URL=http://localhost:3000
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - app-network

  # Backend - FastAPI
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    volumes:
      - ./backend:/app
    environment:
      - POSTGRES_HOST=db
      - POSTGRES_PORT=5432
      - POSTGRES_DB=biuai
      - POSTGRES_USER=biuai
      - POSTGRES_PASSWORD=biuai123
      - JWT_SECRET=biuai-super-secret-key-2024
      - ACCESS_TOKEN_EXPIRE_MINUTES=60
      - MODEL_SERVER=http://model-server:8000
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - MCP_MEMORY_SERVICE_URL=http://mcp-memory-server:8001
      - MCP_CHATBOT_SERVICE_URL=http://mcp-chatbot-service:8002
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      model-server:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - app-network

  # PostgreSQL
  db:
    image: postgres:15-alpine
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./data/init.sql:/docker-entrypoint-initdb.d/init.sql
    environment:
      - POSTGRES_DB=biuai
      - POSTGRES_USER=biuai
      - POSTGRES_PASSWORD=biuai123
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U biuai -d biuai"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - app-network

  # Model Server
  model-server:
    build:
      context: ./model-server
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - ./model-server:/app
      - model_artifacts:/app/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - app-network

  # PostgreSQL Admin
  pgadmin:
    image: dpage/pgadmin4
    ports:
      - "5050:80"
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@biuai.com
      - PGADMIN_DEFAULT_PASSWORD=biuai123
    depends_on:
      - db
    networks:
      - app-network

  # Redis
  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - app-network

  # Jupyter Notebook
  jupyter:
    build:
      context: ./jupyter
      dockerfile: Dockerfile
    ports:
      - "8888:8888"
    volumes:
      - ./jupyter:/home/jovyan/work
      - ./data:/home/jovyan/data
    environment:
      - POSTGRES_HOST=db
      - POSTGRES_PORT=5432
      - POSTGRES_DB=biuai
      - POSTGRES_USER=biuai
      - POSTGRES_PASSWORD=biuai123
    depends_on:
      - db
    networks:
      - app-network

  # MCP Memory Server - Mem0 AI
  mcp-memory-server:
    build:
      context: ./mcp-memory-service
      dockerfile: Dockerfile
    ports:
      - "8001:8001"
    volumes:
      - ./mcp-memory-service:/app
      - mcp_memory_data:/app/data
    environment:
      - MCP_SERVER_HOST=0.0.0.0
      - MCP_SERVER_PORT=8001
      - MEM0_API_KEY=a4ed31ec-0cee-4385-b796-4dd33ef1ffb9
      - MEM0_PROFILE=resident-coral-8A1GGg
      - MEM0_SERVER_URL=https://server.smithery.ai/@mem0ai/mem0-memory-mcp/mcp
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 15s
      timeout: 10s
      retries: 5
    networks:
      - app-network

  # Ollama - IA Local Gratuita
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_MODELS=/root/.ollama/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - app-network
    deploy:
      resources:
        reservations:
          memory: 2G

  # MCP Chatbot Service - Bi UAI Bot
  mcp-chatbot-service:
    build:
      context: ./mcp-chatbot-service
      dockerfile: Dockerfile
    ports:
      - "8002:8002"
    volumes:
      - ./mcp-chatbot-service:/app
      - chatbot_data:/app/data
    environment:
      - MCP_SERVER_HOST=0.0.0.0
      - MCP_SERVER_PORT=8002
      - OLLAMA_BASE_URL=http://ollama:11434
      - BACKEND_API_URL=http://backend:3000
      - REDIS_URL=redis://redis:6379/1
      - BOT_NAME=Bi UAI Bot Administrador
    depends_on:
      - ollama
      - backend
      - redis
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 15s
      timeout: 10s
      retries: 5
    networks:
      - app-network

networks:
  app-network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  model_artifacts:
  mcp_memory_data:
  ollama_data:
  chatbot_data: 